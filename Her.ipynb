{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T06:13:57.036671Z",
     "start_time": "2024-09-10T06:13:56.303865Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Her\n",
    "\n",
    "her = Her(\n",
    "    model = \"gpt-4o\", # gpt-4o or anthropic\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T06:14:08.319116Z",
     "start_time": "2024-09-10T06:13:57.037739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: python\n",
      "Chat history saved to TalkWithHer.html\n",
      "It appears that the links on the webpage you are scraping have href attributes set to `javascript:void(0)`, which effectively means that they do not lead to any new URLs. This typically happens when the links are designed to trigger JavaScript functions rather than navigate to a different webpage.\n",
      "\n",
      "Here are a few steps you can take to handle this situation:\n",
      "\n",
      "1. **Check for onclick Handlers:**\n",
      "   Sometimes, JavaScript links are used to perform actions through `onclick` handlers. You can look for `onclick` attributes within the `<a>` tags to understand what actions are being performed.\n",
      "   \n",
      "   ```python\n",
      "   for link in soup.find_all('a', href=True):\n",
      "       if 'onclick' in link.attrs:\n",
      "           print(link['onclick'])\n",
      "   ```\n",
      "\n",
      "2. **Look for Data Attributes:**\n",
      "   The links might use data attributes to store URLs or actions that are processed by JavaScript. For instance:\n",
      "   \n",
      "   ```python\n",
      "   for link in soup.find_all('a', href=True):\n",
      "       if 'data-url' in link.attrs:\n",
      "           new_url = urljoin(url, link['data-url'])\n",
      "           # Process new_url\n",
      "   ```\n",
      "\n",
      "3. **Extract URLs from JavaScript Code:**\n",
      "   If the URLs are embedded in JavaScript code, you might need to parse the JavaScript to extract the URLs. This can be tricky and might involve using libraries like `js2py` or writing custom regular expressions.\n",
      "\n",
      "4. **Inspect the Web Page:**\n",
      "   Manually inspect the webpage using browser developer tools (right-click > Inspect) to better understand what mechanism the links use to navigate. Look for hidden inputs, data attributes, or network requests being made.\n",
      "\n",
      "5. **Automate with a Browser:**\n",
      "   Use a tool like Selenium to interact with the webpage as a browser would. This can help you deal with JavaScript-heavy sites where URLs are dynamically generated or updated.\n",
      "\n",
      "   - Install Selenium: \n",
      "     ```\n",
      "     pip install selenium\n",
      "     ```\n",
      "\n",
      "   - Use Selenium to Fetch the URLs:\n",
      "     ```python\n",
      "     from selenium import webdriver\n",
      "     from selenium.webdriver.common.by import By\n",
      "\n",
      "     driver = webdriver.Chrome()  # You might need to specify the path to the chromedriver executable\n",
      "     driver.get('http://example.com')\n",
      "\n",
      "     links = driver.find_elements(By.TAG_NAME, 'a')\n",
      "     for link in links:\n",
      "         href = link.get_attribute('href')\n",
      "         print(href)\n",
      "\n",
      "     driver.quit()\n",
      "     ```\n",
      "\n",
      "By exploring these options, you should be able to find a way to deal with the links set to `javascript:void(0)` and extract the necessary URLs.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "if html:\n",
    "    content = self.parse_content(html)\n",
    "    scraped_content.append((url, content))\n",
    "    visited.add(url)\n",
    "    self.add_to_cache(url, content)\n",
    "\n",
    "    # Find more links\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    for link in soup.find_all('a', href=True):\n",
    "        new_url = urljoin(url, link['href'])\n",
    "\n",
    "the output is: \n",
    "javascript:void(0)\n",
    "\n",
    "there are many links in the webpage, but the output is javascript:void(0) for all the links.\n",
    "\n",
    "can you help me with this?\n",
    "\n",
    "\"\"\"\n",
    "response = her.ask(\n",
    "    query,\n",
    "    role = \"You are general assistant\",\n",
    ")\n",
    "\n",
    "print (response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
