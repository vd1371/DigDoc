{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T05:37:03.876885Z",
     "start_time": "2024-09-05T05:37:03.872371Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import generate_response, get_context_for_her, save_response_to_her\n",
    "\n",
    "model = \"gpt-4o\" # gpt4o or anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T05:40:08.410811Z",
     "start_time": "2024-09-05T05:40:01.728698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response saved to Her.md\n",
      "Sure! Your original code creates the shifted DataFrame and then iterates through every pair of columns to compute their correlation with a lag. This can be inefficient, especially with larger DataFrames. Below, I'll provide an optimized version that leverages vectorized operations in pandas and numpy to speed up the entire process. \n",
      "\n",
      "We can use the `pairwise` function from the `sklearn.metrics` module to calculate the correlation matrix in a vectorized way. This will bypass the need for nested loops. Note that I assume the DataFrame doesn't contain excessive null values since handling null values can also impact performance:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.metrics import pairwise_distances\n",
      "\n",
      "def get_corr_df(return_df):\n",
      "    # Create the lead shifted DataFrame once\n",
      "    return_df_lead = return_df.shift(1)\n",
      "    \n",
      "    # Calculate the pairwise correlation matrices using numpy\n",
      "    correlations = (return_df.T @ return_df_lead) / (len(return_df) - 1)\n",
      "\n",
      "    # Reset the diagonal to zero since we don't want to compare a column with itself\n",
      "    np.fill_diagonal(corrections.values, 0)\n",
      "\n",
      "    # Convert the resulting DataFrame into a long-format DataFrame\n",
      "    corr_df = correlations.unstack().reset_index()\n",
      "    corr_df.columns=['Lead', 'Lag', 'corr']\n",
      "\n",
      "    # Filtering out autocorrelations and irrelevant pairs\n",
      "    corr_df = corr_df[corr_df['Lead'] != corr_df['Lag']]\n",
      "\n",
      "    return corr_df\n",
      "\n",
      "# Example usage:\n",
      "# return_df = pd.DataFrame({\n",
      "#     'A': np.random.randn(100),\n",
      "#     'B': np.random.randn(100),\n",
      "#     'C': np.random.randn(100)\n",
      "# })\n",
      "\n",
      "# optimized_corr_df = get_corr_df(return_df)\n",
      "# print(optimized_corr_df)\n",
      "```\n",
      "\n",
      "Key changes and optimizations:\n",
      "\n",
      "1. **Single Shift Operation**: `return_df.shift(1)` is calculated once per the entire DataFrame.\n",
      "2. **Vectorized Correlation Calculation**: Using matrix multiplication to calculate pairwise correlations, which is inherently faster than looping through the columns.\n",
      "3. **Diagonal Reset**: Efficient way to set diagonal elements to zero using numpy's `fill_diagonal`.\n",
      "\n",
      "This code should run much faster, especially for larger DataFrames since it minimizes the use of loops and utilizes efficient matrix operations with numpy and pandas.\n"
     ]
    }
   ],
   "source": [
    "role = \"You are general assistant\"\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "def get_corr_df(return_df):\n",
    "\n",
    "    corr_holder = []\n",
    "    return_df_lead = return_df.shift(1)\n",
    "    for lead in return_df.columns:\n",
    "        for lag in return_df.columns:\n",
    "            if lead == lag:\n",
    "                continue\n",
    "\n",
    "            return_lag = return_df[lag]\n",
    "            return_lead = return_df_lead[lead]\n",
    "\n",
    "            if return_lead.isnull().sum() > 1 or return_lag.isnull().sum() > 1:\n",
    "                corr_holder.append([lead, lag, 0])\n",
    "                continue\n",
    "\n",
    "            corr = return_lead.corr(return_lag)\n",
    "            corr_holder.append([lead, lag, corr])\n",
    "\n",
    "    corr_df = pd.DataFrame(corr_holder, columns=['Lead', 'Lag', 'corr'])\n",
    "\n",
    "    corr_df = corr_df.pivot(index='Lead', columns='Lag', values='corr')\n",
    "\n",
    "    diff = corr_df.T - corr_df\n",
    "\n",
    "    # Make it 2D with lead and lag and corr as the columns similar to the original corr_df\n",
    "    diff = diff.stack().reset_index()\n",
    "    diff.columns = ['Lead', 'Lag', 'corr']\n",
    "\n",
    "    return diff\n",
    "    \n",
    "    can you make this code considerably faster?\n",
    "    \n",
    "    I want every column in return_df to be compared with every other column in return_df.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = generate_response(query, get_context_for_her(), role, model = model)\n",
    "\n",
    "save_response_to_her(f\"{response}\\n\\n\")\n",
    "print (response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
