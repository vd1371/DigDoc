{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T07:25:14.879937Z",
     "start_time": "2024-09-16T07:25:06.049831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eUlLuc8AAAAJ&citation_for_view=eUlLuc8AAAAJ:YsMSGLbcyi4C\n"
     ]
    }
   ],
   "source": [
    "from utils import DigDoc\n",
    "\n",
    "# directory:\n",
    "#   - a folder on your local machine, where the documents are searched, \"web\", or \"google\"\n",
    "#   - \"web\" for web scrapping, you need to provide links in the targets, it will dig until the max_depth and max_pages\n",
    "#   - \"google\" for Google search, you need to provide the sites in the target, or \"all\" for all the searches that google provides\n",
    "\n",
    "# The code cannot catch typos and other errors in the target, so make sure to provide the correct links\n",
    "\n",
    "digger = DigDoc(\n",
    "    directory = \"web\",\n",
    "    model = \"gpt-4o\",\n",
    "    project_name = \"Test\",\n",
    "    target = [\n",
    "        \"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eUlLuc8AAAAJ&citation_for_view=eUlLuc8AAAAJ:YsMSGLbcyi4C\",\n",
    "    ],\n",
    "    reindex = True\n",
    ")\n",
    "\n",
    "# For web scrapping\n",
    "digger.set_scrapping_params(\n",
    "    max_depth = 2,\n",
    "    max_pages = 10,\n",
    "    load_from_cache = False\n",
    ")\n",
    "\n",
    "digger.dig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T07:25:20.105851Z",
     "start_time": "2024-09-16T07:25:18.034156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat history saved to projects/Test/ChatHistory.html\n",
      "Answer: The paper addresses the research gap of insufficient quantitative analysis on the impact of economic factors on construction cost estimation by using deep neural networks (DNN) and SHapley Additive exPlanations (SHAP) to incorporate and interpret these factors, demonstrating their significant role in improving cost prediction accuracy.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "\n",
    "write one sentence about the paper, tell me the research gap and the solution, veru short and concise\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "answer, source_docs = digger.answer(query)\n",
    "\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
